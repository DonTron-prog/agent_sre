from typing import Union
import openai
from pydantic import Field
from atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig
from atomic_agents.lib.base.base_io_schema import BaseIOSchema
from atomic_agents.lib.components.agent_memory import AgentMemory
from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator, SystemPromptContextProviderBase

from orchestration_agent.tools.searxng_search import (
    SearxNGSearchTool,
    SearxNGSearchToolConfig,
    SearxNGSearchToolInputSchema,
    SearxNGSearchToolOutputSchema,
)
from orchestration_agent.tools.calculator import (
    CalculatorTool,
    CalculatorToolConfig,
    CalculatorToolInputSchema,
    CalculatorToolOutputSchema,
)
from orchestration_agent.tools.rag_search import (
    RAGSearchTool,
    RAGSearchToolConfig,
    RAGSearchToolInputSchema,
    RAGSearchToolOutputSchema
)
from orchestration_agent.tools.deep_research import (
    DeepResearchTool,
    DeepResearchToolConfig,
    DeepResearchToolInputSchema,
    DeepResearchToolOutputSchema,
)

import instructor
from datetime import datetime
from dotenv import load_dotenv
import os 

from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax

load_dotenv()  # Load environment variables from .env file

########################
# INPUT/OUTPUT SCHEMAS #
########################
class OrchestratorInputSchema(BaseIOSchema):
    """Input schema for the SRE Orchestrator Agent. Contains the system alert and its context."""

    system_alert: str = Field(..., description="The system alert received (e.g., 'High CPU utilization on server X').")
    system_context: str = Field(..., description="Contextual information about the system experiencing the alert (e.g., 'Production web server, recent deployment v1.2').")


class OrchestratorOutputSchema(BaseIOSchema):
    """Combined output schema for the Orchestrator Agent. Contains the tool to use and its parameters."""

    tool: str = Field(..., description="The tool to use: 'search', 'calculator', 'rag', or 'deep-research'")
    tool_parameters: Union[SearxNGSearchToolInputSchema, CalculatorToolInputSchema, RAGSearchToolInputSchema, DeepResearchToolInputSchema] = Field(
        ..., description="The parameters for the selected tool"
    )


class FinalAnswerSchema(BaseIOSchema):
    """Schema for the final answer generated by the Orchestrator Agent."""

    final_answer: str = Field(..., description="The final answer generated based on the tool output and user query.")


#######################
# AGENT CONFIGURATION #
#######################
class OrchestratorAgentConfig(BaseAgentConfig):
    """Configuration for the Orchestrator Agent."""

    searxng_config: SearxNGSearchToolConfig
    calculator_config: CalculatorToolConfig
    rag_config: RAGSearchToolConfig
    deep_research_config: DeepResearchToolConfig


#####################
# CONTEXT PROVIDERS #
#####################
class CurrentDateProvider(SystemPromptContextProviderBase):
    def __init__(self, title):
        super().__init__(title)
        self.date = datetime.now().strftime("%Y-%m-%d")

    def get_info(self) -> str:
        return f"Current date in format YYYY-MM-DD: {self.date}"

################
# TOOL EXECUTION #
################
def execute_tool(
    searxng_tool: SearxNGSearchTool, calculator_tool: CalculatorTool, rag_tool: RAGSearchTool, deep_research_tool: DeepResearchTool, orchestrator_output: OrchestratorOutputSchema
) -> Union[SearxNGSearchToolOutputSchema, CalculatorToolOutputSchema, RAGSearchToolOutputSchema, DeepResearchToolOutputSchema]:
    if orchestrator_output.tool in ("search", "web-search"):
        if not isinstance(orchestrator_output.tool_parameters, SearxNGSearchToolInputSchema):
            raise ValueError(f"Invalid parameters for search tool: {orchestrator_output.tool_parameters}")
        return searxng_tool.run(orchestrator_output.tool_parameters)
    elif orchestrator_output.tool == "calculator":
        if not isinstance(orchestrator_output.tool_parameters, CalculatorToolInputSchema):
            raise ValueError(f"Invalid parameters for calculator tool: {orchestrator_output.tool_parameters}")
        return calculator_tool.run(orchestrator_output.tool_parameters)
    elif orchestrator_output.tool == "rag":
        if not isinstance(orchestrator_output.tool_parameters, RAGSearchToolInputSchema):
            raise ValueError(f"Invalid parameters for RAG tool: {orchestrator_output.tool_parameters}")
        return rag_tool.run(orchestrator_output.tool_parameters)
    elif orchestrator_output.tool == "deep-research":
        if not isinstance(orchestrator_output.tool_parameters, DeepResearchToolInputSchema):
            raise ValueError(f"Invalid parameters for deep research tool: {orchestrator_output.tool_parameters}")
        return deep_research_tool.run(orchestrator_output.tool_parameters)
    else:
        raise ValueError(f"Unknown tool: {orchestrator_output.tool}")

###########################
# ORCHESTRATOR FUNCTIONS  #
###########################

def load_configuration():
    """Load configuration settings from environment variables or config files."""
    config = {
        "openai_api_key": os.getenv("OPENAI_API_KEY"),
        "model_name": os.getenv("MODEL_NAME", "gpt-4o-mini"),
        "searxng_base_url": os.getenv("SEARXNG_BASE_URL", "http://localhost:8080"),
        "knowledge_base_dir": os.path.join(os.path.dirname(__file__), "..", "knowledge_base_sre"),
        "persist_dir": os.path.join(os.path.dirname(__file__), "..", "sre_chroma_db"),
        "recreate_rag_collection": os.getenv("RECREATE_RAG_COLLECTION", "False").lower() == "true",
        "force_reload_rag_docs": os.getenv("FORCE_RELOAD_RAG_DOCS", "False").lower() == "true",
        "max_search_results": int(os.getenv("MAX_SEARCH_RESULTS", 3))
    }
    return config

def setup_environment_and_client(config):
    """Set up environment variables and initialize the OpenAI client."""
    client = instructor.from_openai(openai.OpenAI(api_key=config["openai_api_key"]))
    return client

def create_orchestrator_agent(client, model_name):
    """Create and configure the orchestrator agent instance."""
    system_prompt_generator = SystemPromptGenerator(
        background=[
            "You are an SRE Orchestrator Agent. Your primary role is to analyze a system alert and its associated context. Based on this analysis, you must decide which tool (RAG, web-search, deep-research, or calculator) will provide the most valuable additional information or context for a subsequent reflection agent to understand and act upon the alert.",
            "Use the RAG (Retrieval Augmented Generation) tool for querying internal SRE knowledge bases. This includes runbooks, incident histories, post-mortems, architectural diagrams, service dependencies, and internal documentation related to the alerted system or similar past issues.",
            "Use the web-search tool for finding external information. This includes searching for specific error codes, CVEs (Common Vulnerabilities and Exposures), documentation for third-party software or services, status pages of external dependencies, or general troubleshooting guides from the broader internet.",
            "Use the deep-research tool when you need comprehensive, multi-source research on complex topics. This tool automatically generates multiple search queries, scrapes content from multiple sources, and synthesizes comprehensive answers. Use this for complex troubleshooting scenarios, emerging technologies, or when you need detailed analysis of unfamiliar systems or error patterns.",
            "Use the calculator tool if the alert involves specific metrics, thresholds, or requires calculations to determine severity, impact (e.g., error budget consumption), or trends.",
        ],
        output_instructions=[
            "Carefully analyze the provided 'system_alert' and 'system_context'.",
            "Determine if the most valuable next step is to: query internal knowledge (RAG), search for external information (web-search), perform comprehensive research (deep-research), or perform a calculation (calculator).",
            "If RAG is chosen: use the 'rag' tool. Formulate a specific question for the RAG system based on the alert and context to retrieve relevant internal documentation (e.g., 'Find runbooks for high CPU on web servers', 'Retrieve incident history for ORA-12514 on payment_db').",
            "If web-search is chosen: use the 'search' tool. Provide 1-3 concise and relevant search queries based on the alert and context (e.g., 'ORA-12514 TNS listener error Oracle', 'Kubernetes Pod CrashLoopBackOff OOMKilled troubleshooting').",
            "If deep-research is chosen: use the 'deep-research' tool. Provide a comprehensive research question that requires analysis of multiple sources and synthesis of information (e.g., 'Research ExtPluginReplicationError Code 7749 in experimental-geo-sync-plugin v0.1.2 and provide troubleshooting guidance', 'Analyze Java OutOfMemoryError patterns in Kubernetes microservices and provide resolution strategies').",
            "If calculator is chosen: use the 'calculator' tool. Provide the mathematical expression needed (e.g., if latency increased from 50ms to 500ms, an expression could be '500 / 50' to find the factor of increase).",
            "Format your output strictly according to the OrchestratorOutputSchema.",
        ],
    )
    
    agent = BaseAgent(
        BaseAgentConfig(
            client=client,
            model=model_name,
            system_prompt_generator=system_prompt_generator,
            input_schema=OrchestratorInputSchema,
            output_schema=OrchestratorOutputSchema,
        )
    )
    
    agent.register_context_provider("current_date", CurrentDateProvider("Current Date"))
    
    return agent

def initialize_tools(config):
    """Initialize all required tools with their configurations."""
    searxng_tool = SearxNGSearchTool(
        SearxNGSearchToolConfig(
            base_url=config["searxng_base_url"],
            max_results=config["max_search_results"]
        )
    )
    
    calculator_tool = CalculatorTool(CalculatorToolConfig())
    
    rag_tool_config = RAGSearchToolConfig(
        docs_dir=config["knowledge_base_dir"],
        persist_dir=config["persist_dir"],
        recreate_collection_on_init=config["recreate_rag_collection"],
        force_reload_documents=config["force_reload_rag_docs"]
    )
    rag_tool = RAGSearchTool(config=rag_tool_config)
    
    deep_research_tool = DeepResearchTool(
        DeepResearchToolConfig(
            searxng_base_url=config["searxng_base_url"],
            max_search_results=config["max_search_results"]
        )
    )
    
    return {
        "searxng": searxng_tool,
        "calculator": calculator_tool,
        "rag": rag_tool,
        "deep_research": deep_research_tool
    }

def prepare_input_schema(alert_data):
    """Convert raw alert data into a properly formatted input schema."""
    return OrchestratorInputSchema(
        system_alert=alert_data["alert"], 
        system_context=alert_data["context"]
    )

def execute_orchestration_pipeline(agent, input_schema):
    """Run the orchestrator agent to determine which tool to use."""
    return agent.run(input_schema)

def handle_tool_execution(orchestrator_output, tools):
    """Execute the appropriate tool based on the orchestrator's decision."""
    return execute_tool(
        tools["searxng"],
        tools["calculator"],
        tools["rag"],
        tools["deep_research"],
        orchestrator_output
    )

def generate_final_answer(agent, input_schema, tool_response):
    """Generate a final answer based on the tool's output."""
    original_schema = agent.output_schema
    agent.output_schema = FinalAnswerSchema
    
    agent.memory.add_message("system", tool_response)

    final_answer_obj = agent.run(input_schema)
    
    agent.output_schema = original_schema
    
    return final_answer_obj

def reset_agent_memory(agent):
    """Reset the agent's memory for the next interaction."""
    agent.memory = AgentMemory()

def process_single_alert(agent, tools, alert_data, console, generate_final_answer_flag=False):
    """Process a single alert through the complete orchestration pipeline."""
    console.print(Panel(
        f"[bold cyan]System Alert:[/bold cyan] {alert_data['alert']}\n"
        f"[bold cyan]System Context:[/bold cyan] {alert_data['context']}",
        expand=False
    ))
    
    input_schema = prepare_input_schema(alert_data)
    
    orchestrator_output = execute_orchestration_pipeline(agent, input_schema)
    
    console.print("\n[bold magenta]Orchestrator Output:[/bold magenta]")
    orchestrator_syntax = Syntax(
        str(orchestrator_output.model_dump_json(indent=2)),
        "json",
        theme="monokai",
        line_numbers=True
    )
    console.print(orchestrator_syntax)
    
    tool_response = handle_tool_execution(orchestrator_output, tools)
    
    console.print("\n[bold green]Tool Output:[/bold green]")
    output_syntax = Syntax(
        str(tool_response.model_dump_json(indent=2)),
        "json",
        theme="monokai",
        line_numbers=True
    )
    console.print(output_syntax)
    
    console.print("\n" + "-" * 80 + "\n")
    
    # Handle final answer generation based on tool type
    if generate_final_answer_flag:
        if orchestrator_output.tool == "deep-research":
            # Deep research already provides comprehensive answer, no need to re-analyze
            console.print(f"\n[bold blue]Research Answer:[/bold blue] {tool_response.answer}")
        else:
            # Other tools return raw data that needs final answer generation
            final_answer_obj = generate_final_answer(agent, input_schema, tool_response)
            console.print(f"\n[bold blue]Final Answer:[/bold blue] {final_answer_obj.final_answer}")
    
    reset_agent_memory(agent)

def run_example_scenarios(agent, tools, example_data, console, generate_final_answer_flag=False):
    """Run through a list of example scenarios."""
    console.print(Panel(
        agent.system_prompt_generator.generate_prompt(), 
        title="System Prompt", 
        expand=False
    ))
    console.print("\n")
    
    for alert_input in example_data:
        process_single_alert(
            agent=agent,
            tools=tools,
            alert_data=alert_input,
            console=console,
            generate_final_answer_flag=generate_final_answer_flag
        )

#######################
# MAIN EXECUTION FLOW #
#######################
if __name__ == "__main__":
    config = load_configuration()
    
    openai_client = setup_environment_and_client(config)
    
    agent = create_orchestrator_agent(
        client=openai_client,
        model_name=config["model_name"]
    )
    
    tool_instances = initialize_tools(config)
    
    console_instance = Console()
    
    example_alerts = [
        {
            "alert": "Critical failure: 'ExtPluginReplicationError: Code 7749 - Sync Timeout with AlphaNode' in 'experimental-geo-sync-plugin v0.1.2' on db-primary.",
            "context": "System: Primary PostgreSQL Database (Version 15.3). Plugin: 'experimental-geo-sync-plugin v0.1.2' (third-party, integrated yesterday for PoC). Service: Attempting geo-replicated read-replica setup. Internal Documentation: Confirmed NO internal documentation or runbooks exist for this experimental plugin or its error codes. Vendor documentation for v0.1.2 is sparse."
        },
        {
            "alert": "Pod CrashLoopBackOff for service 'checkout-service' in Kubernetes cluster 'prod-east-1'. Error log snippet: 'java.lang.OutOfMemoryError: Java heap space'.",
            "context": "System: Kubernetes microservice (Java Spring Boot). Service: Checkout processing. Resource limits: Memory 512Mi, CPU 0.5 core. Traffic: Experiencing 3x normal load due to flash sale."
        },
        {
            "alert": "API endpoint /api/v2/orders returning 503 Service Unavailable for 5% of requests over the last 10 minutes. Latency P99 is 2500ms.",
            "context": "System: API Gateway (Kong) and backend OrderService. Service: Order placement. Dependencies: InventoryService, PaymentService. Current error rate threshold: < 1%. Latency SLO: P99 < 800ms."
        },
        {
            "alert": "Unusual network traffic pattern detected: 'TLS handshake failures increased by 400% from external IPs in APAC region' affecting load balancer 'prod-lb-01'.",
            "context": "System: Production Load Balancer (HAProxy 2.4). Service: Frontend traffic distribution. Recent changes: SSL certificate renewal completed 2 hours ago. Geographic pattern: 85% of failures from previously unseen IP ranges in Asia-Pacific. No internal documentation exists for this specific failure pattern or geographic correlation analysis."
        }
        #{
        #    "alert": "High CPU utilization (95%) on server web-prod-01 for 15 minutes.",
        #    "context": "System: Production Web Server Cluster (nginx, Python/Flask). Service: Main customer-facing website. Recent changes: New deployment v2.3.1 two hours ago. Known issues: Occasional spikes during peak load. Monitoring tool: Prometheus."
        #},
    ]
    
    run_example_scenarios(
        agent=agent,
        tools=tool_instances,
        example_data=example_alerts,
        console=console_instance,
        generate_final_answer_flag=True
    )
