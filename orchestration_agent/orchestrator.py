from typing import Union
import openai
from pydantic import Field
from atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig
from atomic_agents.lib.base.base_io_schema import BaseIOSchema
from atomic_agents.lib.components.agent_memory import AgentMemory
from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator, SystemPromptContextProviderBase

from orchestration_agent.tools.searxng_search import (
    SearxNGSearchTool,
    SearxNGSearchToolConfig,
    SearxNGSearchToolInputSchema,
    SearxNGSearchToolOutputSchema,
)
from orchestration_agent.tools.calculator import (
    CalculatorTool,
    CalculatorToolConfig,
    CalculatorToolInputSchema,
    CalculatorToolOutputSchema,
)
from orchestration_agent.tools.rag_search import (
    RAGSearchTool,
    RAGSearchToolConfig,
    RAGSearchToolInputSchema,
    RAGSearchToolOutputSchema
)

import instructor
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()  # Load environment variables from .env file

########################
# INPUT/OUTPUT SCHEMAS #
########################
class OrchestratorInputSchema(BaseIOSchema):
    """Input schema for the SRE Orchestrator Agent. Contains the system alert and its context."""

    system_alert: str = Field(..., description="The system alert received (e.g., 'High CPU utilization on server X').")
    system_context: str = Field(..., description="Contextual information about the system experiencing the alert (e.g., 'Production web server, recent deployment v1.2').")


class OrchestratorOutputSchema(BaseIOSchema):
    """Combined output schema for the Orchestrator Agent. Contains the tool to use and its parameters."""

    tool: str = Field(..., description="The tool to use: 'search', 'calculator', or 'rag'")
    tool_parameters: Union[SearxNGSearchToolInputSchema, CalculatorToolInputSchema, RAGSearchToolInputSchema] = Field(
        ..., description="The parameters for the selected tool"
    )


class FinalAnswerSchema(BaseIOSchema):
    """Schema for the final answer generated by the Orchestrator Agent."""

    final_answer: str = Field(..., description="The final answer generated based on the tool output and user query.")


#######################
# AGENT CONFIGURATION #
#######################
class OrchestratorAgentConfig(BaseAgentConfig):
    """Configuration for the Orchestrator Agent."""

    searxng_config: SearxNGSearchToolConfig
    calculator_config: CalculatorToolConfig
    rag_config: RAGSearchToolConfig


#####################
# CONTEXT PROVIDERS #
#####################
class CurrentDateProvider(SystemPromptContextProviderBase):
    def __init__(self, title):
        super().__init__(title)
        self.date = datetime.now().strftime("%Y-%m-%d")

    def get_info(self) -> str:
        return f"Current date in format YYYY-MM-DD: {self.date}"


######################
# ORCHESTRATOR AGENT #
######################
orchestrator_agent = BaseAgent(
    BaseAgentConfig(
        client=instructor.from_openai(openai.OpenAI()),
        model="gpt-4o-mini",
        system_prompt_generator=SystemPromptGenerator(
            background=[
                "You are an SRE Orchestrator Agent. Your primary role is to analyze a system alert and its associated context. Based on this analysis, you must decide which tool (RAG, web-search, or calculator) will provide the most valuable additional information or context for a subsequent reflection agent to understand and act upon the alert.",
                "Use the RAG (Retrieval Augmented Generation) tool for querying internal SRE knowledge bases. This includes runbooks, incident histories, post-mortems, architectural diagrams, service dependencies, and internal documentation related to the alerted system or similar past issues.",
                "Use the web-search tool for finding external information. This includes searching for specific error codes, CVEs (Common Vulnerabilities and Exposures), documentation for third-party software or services, status pages of external dependencies, or general troubleshooting guides from the broader internet.",
                "Use the calculator tool if the alert involves specific metrics, thresholds, or requires calculations to determine severity, impact (e.g., error budget consumption), or trends.",
            ],
            output_instructions=[
                "Carefully analyze the provided 'system_alert' and 'system_context'.",
                "Determine if the most valuable next step is to: query internal knowledge (RAG), search for external information (web-search), or perform a calculation (calculator).",
                "If RAG is chosen: use the 'rag' tool. Formulate a specific question for the RAG system based on the alert and context to retrieve relevant internal documentation (e.g., 'Find runbooks for high CPU on web servers', 'Retrieve incident history for ORA-12514 on payment_db').",
                "If web-search is chosen: use the 'search' tool. Provide 1-3 concise and relevant search queries based on the alert and context (e.g., 'ORA-12514 TNS listener error Oracle', 'Kubernetes Pod CrashLoopBackOff OOMKilled troubleshooting').",
                "If calculator is chosen: use the 'calculator' tool. Provide the mathematical expression needed (e.g., if latency increased from 50ms to 500ms, an expression could be '500 / 50' to find the factor of increase).",
                "Format your output strictly according to the OrchestratorOutputSchema.",
            ],
        ),
        input_schema=OrchestratorInputSchema,
        output_schema=OrchestratorOutputSchema,
    )
)

# Register the current date provider
orchestrator_agent.register_context_provider("current_date", CurrentDateProvider("Current Date"))


def execute_tool(
    searxng_tool: SearxNGSearchTool, calculator_tool: CalculatorTool, rag_tool: RAGSearchTool, orchestrator_output: OrchestratorOutputSchema
) -> Union[SearxNGSearchToolOutputSchema, CalculatorToolOutputSchema, RAGSearchToolOutputSchema]:
    if orchestrator_output.tool in ("search", "web-search"):
        # Ensure the parameters are of the correct type for the tool
        if not isinstance(orchestrator_output.tool_parameters, SearxNGSearchToolInputSchema):
            raise ValueError(f"Invalid parameters for search tool: {orchestrator_output.tool_parameters}")
        return searxng_tool.run(orchestrator_output.tool_parameters)
    elif orchestrator_output.tool == "calculator":
        if not isinstance(orchestrator_output.tool_parameters, CalculatorToolInputSchema):
            raise ValueError(f"Invalid parameters for calculator tool: {orchestrator_output.tool_parameters}")
        return calculator_tool.run(orchestrator_output.tool_parameters)
    elif orchestrator_output.tool == "rag":
        if not isinstance(orchestrator_output.tool_parameters, RAGSearchToolInputSchema):
            raise ValueError(f"Invalid parameters for RAG tool: {orchestrator_output.tool_parameters}")
        return rag_tool.run(orchestrator_output.tool_parameters)
    else:
        raise ValueError(f"Unknown tool: {orchestrator_output.tool}")


#################
# EXAMPLE USAGE #
#################
if __name__ == "__main__":
    import os
    from dotenv import load_dotenv
    from rich.console import Console
    from rich.panel import Panel
    from rich.syntax import Syntax

    load_dotenv()

    # Set up the OpenAI client
    client = instructor.from_openai(openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY")))

    # Initialize the tools
    searxng_tool = SearxNGSearchTool(SearxNGSearchToolConfig(base_url="http://localhost:8080", max_results=3)) # Replace with your SearxNG instance
    calculator_tool = CalculatorTool(CalculatorToolConfig())
    # Configure RAG tool - create a knowledge_base directory in the SRE-agent folder or update path
    # Ensure OPENAI_API_KEY is set in .env or environment
    knowledge_base_dir = os.path.join(os.path.dirname(__file__), "..", "knowledge_base_sre")
    print(f"!!! DEBUG 1")   
    rag_tool_config = RAGSearchToolConfig(
        docs_dir=knowledge_base_dir,
        persist_dir=os.path.join(os.path.dirname(__file__), "..", "sre_chroma_db"),
        recreate_collection_on_init=False, # Set to False after first run if you want to persist DB
        force_reload_documents=False # Set to True if you want to force reindexing of documents
    )
    rag_tool = RAGSearchTool(config=rag_tool_config)

    # Initialize Rich console
    console = Console()

    # Print the full system prompt
    console.print(Panel(orchestrator_agent.system_prompt_generator.generate_prompt(), title="System Prompt", expand=False))
    console.print("\n")

    # Example inputs
    inputs = [
        #{
        #    "alert": "High CPU utilization (95%) on server web-prod-01 for 15 minutes.",
        #    "context": "System: Production Web Server Cluster (nginx, Python/Flask). Service: Main customer-facing website. Recent changes: New deployment v2.3.1 two hours ago. Known issues: Occasional spikes during peak load. Monitoring tool: Prometheus."
        #},
        {
            "alert": "Critical failure: 'ExtPluginReplicationError: Code 7749 - Sync Timeout with AlphaNode' in 'experimental-geo-sync-plugin v0.1.2' on db-primary.",
            "context": "System: Primary PostgreSQL Database (Version 15.3). Plugin: 'experimental-geo-sync-plugin v0.1.2' (third-party, integrated yesterday for PoC). Service: Attempting geo-replicated read-replica setup. Internal Documentation: Confirmed NO internal documentation or runbooks exist for this experimental plugin or its error codes. Vendor documentation for v0.1.2 is sparse."
        },
        {
            "alert": "Pod CrashLoopBackOff for service 'checkout-service' in Kubernetes cluster 'prod-east-1'. Error log snippet: 'java.lang.OutOfMemoryError: Java heap space'.",
            "context": "System: Kubernetes microservice (Java Spring Boot). Service: Checkout processing. Resource limits: Memory 512Mi, CPU 0.5 core. Traffic: Experiencing 3x normal load due to flash sale."
        },
        {
            "alert": "API endpoint /api/v2/orders returning 503 Service Unavailable for 5% of requests over the last 10 minutes. Latency P99 is 2500ms.",
            "context": "System: API Gateway (Kong) and backend OrderService. Service: Order placement. Dependencies: InventoryService, PaymentService. Current error rate threshold: < 1%. Latency SLO: P99 < 800ms."
        }
    ]

    for item_input in inputs:
        console.print(Panel(f"[bold cyan]System Alert:[/bold cyan] {item_input['alert']}\n[bold cyan]System Context:[/bold cyan] {item_input['context']}", expand=False))

        # Create the input schema
        input_schema = OrchestratorInputSchema(system_alert=item_input["alert"], system_context=item_input["context"])

        # Print the input schema
        console.print("\n[bold yellow]Generated Input Schema:[/bold yellow]")
        input_syntax = Syntax(str(input_schema.model_dump_json(indent=2)), "json", theme="monokai", line_numbers=True)
        console.print(input_syntax)

        # Run the orchestrator to get the tool selection and input
        orchestrator_output = orchestrator_agent.run(input_schema)

        # Print the orchestrator output
        console.print("\n[bold magenta]Orchestrator Output:[/bold magenta]")
        orchestrator_syntax = Syntax(
            str(orchestrator_output.model_dump_json(indent=2)), "json", theme="monokai", line_numbers=True
        )
        console.print(orchestrator_syntax)

        # Run the selected tool
        response = execute_tool(searxng_tool, calculator_tool, rag_tool, orchestrator_output)

        # Print the tool output
        console.print("\n[bold green]Tool Output:[/bold green]")
        output_syntax = Syntax(str(response.model_dump_json(indent=2)), "json", theme="monokai", line_numbers=True)
        console.print(output_syntax)

        console.print("\n" + "-" * 80 + "\n")

        # The SRE orchestrator's primary output is the tool choice and its parameters.
        # The output of the selected tool will be consumed by a subsequent reflection agent.
        # Therefore, generating a "final_answer" here might not be necessary for the SRE pipeline.
        # If a final summarization or handoff message is needed from this agent, this section can be adapted.
        # For now, we'll comment it out to focus on the tool selection aspect.
        #
        orchestrator_agent.output_schema = FinalAnswerSchema
        orchestrator_agent.memory.add_message("system", response) # 'response' here is the tool's output
        final_answer = orchestrator_agent.run(input_schema) # This would re-run the LLM with the tool output in memory
        console.print(f"\n[bold blue]Final Answer:[/bold blue] {final_answer.final_answer}")
        orchestrator_agent.output_schema = OrchestratorOutputSchema

        # Reset the memory after each response if you are doing multiple turns in the example
        orchestrator_agent.memory = AgentMemory()
